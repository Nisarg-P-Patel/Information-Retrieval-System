# -*- coding: utf-8 -*-
"""Mini Search Engine.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PDHM2ys4BkoggqEf9rl2WOje8jZwzQSn

# Aim:- Make a mini search engine

Sub Task :-
    1. Generate TF-IDF vectors for give corpus
    2. 2-3 Domains of documents (In this Name of Player is considered :- )
    3. Search plot as query and suggest similar Player from Dataset
    4. GUI Implementation Optional

# Packages Used

NLTK :-
    Used for basic text pre processing structure.
    
Sklearn :-
    For generating tfidf matrix, cosine_similarity
    
Pandas:-
    For accessing the data & filtering it
"""

# Importing necessary libraries

import nltk
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

import pandas as pd

"""# Fetching the data from csv file"""

df = pd.read_csv("Shakespeare_data.csv")
df.head()

"""# Filtering the data for the purpose"""

del [df['Dataline'],df['PlayerLinenumber'],df['ActSceneLine']]
df.head()

df['Player'].value_counts()[:10]

requires = {'GLOUCESTER':0,'HAMLET':1,'IAGO':2,'FALSTAFF':3,'KING HENRY V':4,'BRUTUS':5,'OTHELLO':6,'MARK ANTONY':7,'KING HENRY VI':8,'DUKE VINCENTIO':9}
df = df[df['Player'].isin(requires)]
df.head()
# df['Player'].value_counts()

print('Size of dataset :-',len(df))

df.reset_index(drop=True,inplace=True)
print(df)

temp=df.groupby('Player')
temp.first()

"""# Pre-processing the data"""

def toLower(sentence):
    return sentence.lower()

def tokenizer(sentence):
    tokens = list(set(nltk.word_tokenize(sentence)))
    return tokens

def stopwords_removal(tokens):
    stop_words = nltk.corpus.stopwords.words('english')
    stop_words.extend([',','?','""',"''",'.','!', "'",'"',"'d","'ll",'[',']','--',':',';','///'])
    filtered_tokens = [i for i in tokens if not i in stop_words]
    return filtered_tokens

def stemming(tokens):
    stemmer = nltk.stem.porter.PorterStemmer()
    stemmed_tokens = [stemmer.stem(i) for i in tokens]
    return stemmed_tokens

def pre_process(text):
    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]
    tokens = stopwords_removal(tokens)
    stems = stemming(tokens)
    return stems

#define vectorizer parameters
tfidf_vectorizer = TfidfVectorizer(max_features=15000,
                                 use_idf=True,tokenizer=pre_process)

tfidf_matrix = tfidf_vectorizer.fit_transform(df['PlayerLine']) #fit the vectorizer to synopses

print(tfidf_matrix.shape)

terms = tfidf_vectorizer.get_feature_names()
print(terms)

"""# Finding cosine similarity"""

def get_cosine_matrix(sentence):
    vect = tfidf_vectorizer.transform([sentence])
    dictionary = dict()
    for i in range(tfidf_matrix.shape[0]):
        dictionary[df['Play'].iloc[i]]=1-cosine_similarity(vect,tfidf_matrix[i])[0][0]#1-0-1
    dictionary = dict(sorted(dictionary.items(), key=lambda item: item[1]))
    return dictionary

"""# Inserting the query and find similar search"""

sentence = input("Enter the PlayerLine of Play to get recommendation :- \n")
matrix1 = get_cosine_matrix(sentence)
matrix = list(get_cosine_matrix(sentence).keys())
lst = []
for i in range(5):
    lst.append(matrix[i])
print("\nRelated Plays and Players:- \n",lst)

# some example of queries

# You tread upon my patience: but be sure /// Danger and disobedience in thine eye /// Whose tongue shall ask me for one penny cost /// We licence your departure with your son /// Betwixt that Holmedon and this seat of ours
# More dazzled and drove back his enemies /// Except it be to pray against thy foes /// These news would cause him once more yield the ghost /// Exit /// BISHOP
# But I have that within which passeth show /// It is not nor it cannot come to good /// And makes each petty artery in this body /// That you must teach me. But let me conjure you, by /// Exit
# It speaks against her with the other proofs /// Yet be content /// Is my lord angry /// When it hath blown his ranks into the air /// To kiss in private /// From this time forth I never will speak word
# hostess of the tavern a most sweet wench /// time and oft /// Thou hast the most unsavoury similes and art indeed /// Christendom /// and I paid nothing for it neither, but was paid for
# He has no equal /// Come, sir, come, we know you well enough /// In that there's comfort /// But hearts for the event /// And we will follow
# Escalus /// That does affect it. Once more, fare you well /// Goes all decorum. /// Enter ISABELLA and FRANCISCA /// Even like an o'ergrown lion in a cave,

"""# Learning Outcomes

1. Get detailed knowledge of pre processing steps with it's importnace & technical terms like corpus,vectorize
2. Get to know the importnace of the filtering process for the corpus and methodology
3. Get to know what is cosine similarity,term frquency,tf-idf and their pros&cons.
"""

